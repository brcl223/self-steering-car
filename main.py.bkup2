import pyrealsense2.pyrealsense2 as rs
import numpy as np
import serial # For communicating with Arduino
from time import sleep
#import scipy.signal as sig

#####################################################
# Process Params (i.e. Global Vars)
#####################################################

# Turning Time in seconds.
# Make this larger for larger turns between images.
TURN_TIME_SECS = 0.15
TURN_DIR = 'L' # 'L' for left or 'R' for right. Shouldn't really matter which.
# Opposite of turn dir. So if TURN_DIR = 'L', ANTI_TURN_DIR = 'R'
ANTI_TURN_DIR = 'R'
# Used as an averaging factor for depth calculations
IMG_PIXELS = 640 * 480
NUM_MOVEMENTS = 50
# CHANGE RUN_NUM BEFORE EACH RUN!
RUN_NUM = 4
# Number of seconds to wait between taking images and turning the car
COMMAND_INTERVAL_SECS = 0.5
# Epsilon value for determining if we are within range
# of our turning target (absolute measure)
# TODO: Tune me
TARGET_EPS = 25
# Epsilon value for determining if we are within range
# of our turning target (relative measure)
# TODO: Tune me
TURNING_EPS = 25

#####################################################
# Code Begins Here
#####################################################
def check_peak(data, idx):
    score = 0

    if data[idx] > data[idx - 1]: score += 1
    if data[idx] > data[idx - 2]: score += 1
    if data[idx] > data[idx + 1]: score += 1
    if data[idx] > data[idx + 2]: score += 1

    if score >= 4:
        return True

    return False


def check_valley(data, idx):
    score = 0

    if data[idx] < data[idx - 1]: score += 1
    if data[idx] < data[idx - 2]: score += 1
    if data[idx] < data[idx + 1]: score += 1
    if data[idx] < data[idx + 2]: score += 1

    if score >= 4:
        return True

    return False


def detect_num_extremums(data):
    smooth = smooth_data(data)
    dlen = smooth.shape[0]
    peaks = valls = 0
    vall_idx = []
    peak_idx = []

    if dlen < 5:
        # We don't have enough data to make a decision yet
        return 0, [], []

    # Simple robust "gradient descent" style peak check
    for i in range(2, dlen - 2):
        if check_peak(smooth, i):
            peaks += 1
            peak_idx.append(i)
        elif check_valley(smooth, i):
            valls += 1
            vall_idx.append(i)

    print(f"Num Peaks: {peaks}\nNum Valleys: {valls}")

    assert abs(peaks - valls) <= 1, "Extremums are out of whack!"

    return peaks + valls, peak_idx, vall_idx


def smooth_data(data):
    data = np.array(data)
    dlen = data.shape[0]

    if dlen < 2:
        # This could cause copy issues, but I don't think
        # it is right now
        return data

    smooth_data = np.zeros(data.shape)
    conv_filt = [1/4, 1/2, 1/4]

    smooth_data[0] = np.dot(conv_filt, [data[0], data[0], data[1]])

    for i in range(1, data.shape[0] - 1):
        smooth_data[i] = np.dot(conv_filt, data[i-1:i+2])

    smooth_data[-1] = np.dot(conv_filt, [data[-2], data[-1], data[-1]])

    return smooth_data


# Builds camel graph
def scan_surroundings(arduino, pipeline):
    global NUM_MOVEMENTS, COMMAND_INTERVAL_SECS

    data_points = []
    # This shouldn't be here
    #init_arduino(arduino)

    seg_data_points = []
    lr_data_points = []

    for j in range(NUM_MOVEMENTS):
        sleep(COMMAND_INTERVAL_SECS)
        print(f"Beginning movement {j+1} of {NUM_MOVEMENTS}...")
        data_points.append(get_depth_estimate(pipeline))
        l,f,r = get_segmented_depth_estimates(pipeline)
        print(f"\n###################\nl: {l}\nf: {f}\nr: {r}\n###############\n")
        l2,r2 = get_lr_depth_estimates(pipeline)
        print(f"\n###################\nl2: {l2}\nr2: {r2}\n###############\n")
        sleep(COMMAND_INTERVAL_SECS)

        seg_data_points.append([l,f,r])
        lr_data_points.append([l2,r2])

        num_extremums, _b1, _b2 = detect_num_extremums(data_points)
        if num_extremums >= 4:
            print("Found two peaks and two vallies!")
            break

        print("Turning arduino")
        turn_for_next_img(arduino)

    print("Saving segmented and LR test data...")
    np.savetxt(f"./data/run-{RUN_NUM}-segmented.txt", seg_data_points)
    np.savetxt(f"./data/run-{RUN_NUM}-lr.txt", lr_data_points)

    return data_points, smooth_data(data_points)


# For whatever reason, the first message or so takes a lot longer
# to process than the succeeding calls. So here I just make some
# dummy instructions to drive forwards and back at first so we
# don't have this issue when we begin turning
def init_arduino(arduino):
    print("Initializing Arduino...")
    arduino.write(bytes('S', 'utf-8'))
    sleep(5)
    arduino.write(bytes('F', 'utf-8'))
    sleep(0.5)
    arduino.write(bytes('B', 'utf-8'))
    sleep(0.5)
    arduino.write(bytes('S', 'utf-8'))
    sleep(5)
    print("Arduino initialized!")



def turn_for_next_img(arduino):
    global TURN_TIME_SECS, TURN_DIR
    arduino.write(bytes(TURN_DIR, 'utf-8')) # Turn first...
    sleep(TURN_TIME_SECS)
    arduino.write(bytes('S', 'utf-8')) # ... and then stop


def turn(arduino, direction, duration=TURN_TIME_SECS):
    assert direction == 'L' or direction == 'R', f'Invalid direction chosen: {direction}\nMust be L or R'
    arduino.write(bytes(direction, 'utf-8'))
    sleep(duration)
    arduino.write(bytes('S', 'utf-8'))


def reverse(arduino, duration=TURN_TIME_SECS):
    arduino.write(bytes('B', 'utf-8'))
    sleep(duration)
    arduino.write(bytes('S', 'utf-8'))


# Computes our singular depth value estimate
# trying to find where the nearest objects are
def get_depth_estimate(pipe):
    global IMG_PIXELS
    
    IMG_COUNT = 60 # at 30fps this takes ~2 seconds
    MAX_SKIPPED = 10
    skipped_imgs = 0
    depth_total = 0

    print("Beginning depth estimate...")

    for i in range(IMG_COUNT):
        #print(f"Image {i+1} of {IMG_COUNT}...")

        frames = pipe.wait_for_frames()
        depth = frames.get_depth_frame()

        if not depth:
            skipped_imgs += 1
            if skipped_imgs > MAX_SKIPPED:
                raise Exception("Too many skipped images!")
            continue

        data = np.asanyarray(depth.get_data())
        # This is where different depth functions
        # can be tried out. Could be weighted sum
        # or bounding box (or more)
        depth_total += (data.sum() / IMG_PIXELS)

    # Get average from number of images
    depth_total /= (IMG_COUNT - skipped_imgs)
    print(f"Done!\nDepth Total Estimate: {depth_total}")
    return depth_total



def get_lr_depth_estimates(pipe):
    IMG_COUNT = 60 # at 30fps this takes ~2 seconds
    MAX_SKIPPED = 10
    skipped_imgs = 0

    ldepth_total = 0
    rdepth_total = 0

    LR_IMG_PIXS = 320*480

    print("Beginning LR depth estimate...")

    for i in range(IMG_COUNT):
        #print(f"Image {i+1} of {IMG_COUNT}...")

        frames = pipe.wait_for_frames()
        depth = frames.get_depth_frame()

        if not depth:
            skipped_imgs += 1
            if skipped_imgs > MAX_SKIPPED:
                raise Exception("Too many skipped images!")
            continue

        data = np.asanyarray(depth.get_data())

        ldepth_total += (data[:,0:320].sum() / LR_IMG_PIXS)
        rdepth_total += (data[:,320:640].sum() / LR_IMG_PIXS)

    # Get average from number of images
    ldepth_total /= (IMG_COUNT - skipped_imgs)
    rdepth_total /= (IMG_COUNT - skipped_imgs)

    return ldepth_total, rdepth_total


# Computes our singular depth value estimate
# trying to find where the nearest objects are
def get_segmented_depth_estimates(pipe):
    IMG_COUNT = 60 # at 30fps this takes ~2 seconds
    MAX_SKIPPED = 10
    skipped_imgs = 0

    ldepth_total = 0
    fdepth_total = 0
    rdepth_total = 0

    #left_pixels = 0:213
    #front_pixels = 213:427
    #right_pixels = 427:640

    LR_IMG_PIXS = 213*480
    FR_IMG_PIXS = 214*480

    print("Beginning segmented depth estimate...")

    for i in range(IMG_COUNT):
        #print(f"Image {i+1} of {IMG_COUNT}...")

        frames = pipe.wait_for_frames()
        depth = frames.get_depth_frame()

        if not depth:
            skipped_imgs += 1
            if skipped_imgs > MAX_SKIPPED:
                raise Exception("Too many skipped images!")
            continue

        data = np.asanyarray(depth.get_data())

        ldepth_total += (data[:,0:213].sum() / LR_IMG_PIXS)
        fdepth_total += (data[:,213:427].sum() / FR_IMG_PIXS)
        rdepth_total += (data[:,427:640].sum() / LR_IMG_PIXS)

    # Get average from number of images
    ldepth_total /= (IMG_COUNT - skipped_imgs)
    fdepth_total /= (IMG_COUNT - skipped_imgs)
    rdepth_total /= (IMG_COUNT - skipped_imgs)
    #print(f"Done!\nDepth Total Estimate: {depth_total}")
    return ldepth_total, fdepth_total, rdepth_total


def turn_to_desired_angle(arduino, pipe, data):
    global ANTI_TURN_DIR, TURN_TIME_SECS

    # Find no. of turns needed to get back to minimum
    # from where we're at now
    total_turns = data.shape[0]
    target_depth = np.amin(data)
    target_depth_idx = data.argmin()

    print(f"Total Turns Made: {total_turns}")
    print(f"Min Data: {target_depth}\nMin Idx: {target_depth_idx}")


    # Turn the arduino. It will probably not actually be exactly where
    # we want it, so we'll need to adjust
    turns_to_make = total_turns - target_depth_idx
    turn(arduino, ANTI_TURN_DIR, TURN_TIME_SECS * turns_to_make)

    print(f"Total Turns: {turns_to_make}")

    depth_est = get_depth_estimate(pipe)

    # Figure out which side 
    turn_ctr = 1
    while abs(depth_est - target_depth) < TARGET_EPS:
        l,_f,r = get_segmented_depth_estimates(pipe)
        turn_val = abs(l - r)
        print(f"Depth Est: {depth_est}\nTarget Depth: {target_depth}")
        print(f"Turning Value: {turn_val}")

        if turn_val < TURNING_EPS:
            break
        elif l < r:
            turn(arduino, 'L', TURN_TIME_SECS * turn_ctr)
        else:
            turn(arduino, 'R', TURN_TIME_SECS * turn_ctr)

        turn_ctr += 0.1
        depth_est = get_depth_estimate(pipe)


def get_depth_target(data):
    _b1, _b2, valley_idxs = detect_num_extremums(data)
    v1 = data[valley_idxs[0]]
    v2 = data[valley_idxs[1]]
    return 0.5 * (v1 + v2)


def in_center_of_hall(data):
    _1, _2, valley_idxs = detect_num_extremums(data)
    v1 = data[valley_idxs[0]]
    v2 = data[valley_idxs[1]]
    if abs(v1 - v2) < TARGET_EPS:
        return True

    return False


def reverse_until_centered(arduino, pipe, data):
    d_target = get_depth_target(data)
    turn_ctr = 1
    while abs(d_target - get_depth_estimate(pipe)) < TARGET_EPS:
        reverse(arduino, duration=(TURN_TIME_SECS / turn_ctr))
        turn_ctr += 1
        if turn_ctr > 10:
            break


def main():
    print(f"Beginning run {RUN_NUM}...")

    # Initialize and start camera
    pipeline = rs.pipeline()
    config = rs.config()
    config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
    pipeline.start(config)

    MAX_CALIBRATION_ATTEMPTS = 10
    calibration_attempts = 0
    with serial.Serial('/dev/ttyUSB0', 9600, timeout=10) as arduino:
        init_arduino(arduino)

        while calibration_attempts < MAX_CALIBRATION_ATTEMPTS:
            print("Scanning for data...")
            data, smooth_data = scan_surroundings(arduino, pipeline)

            print("Checking if centered...")
            if in_center_of_hall(smooth_data):
                print("WE ARE CENTERED!")
                break

            print("Turning to desired angle...")
            turn_to_desired_angle(arduino, pipeline, smooth_data)

            print("Reversing to target depth...")
            reverse_until_centered(arduino, pipeline, smooth_data)
            calibration_attempts += 1

    # CHANGE RUN_NUM BEFORE EACH RUN!
    print("Saving data...")
    np.savetxt(f"./data/run-{RUN_NUM}.txt", data)
    np.savetxt(f"./data/run-{RUN_NUM}-smooth.txt", smooth_data)
    print("Run complete!")


if __name__ == '__main__':
    main()
